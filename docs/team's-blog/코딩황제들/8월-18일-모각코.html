<!DOCTYPE html> <html><head>
		<title>8월 18일 모각코</title>
		<base href="..\../">
		<meta id="root-path" root-path="..\../">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0">
		<meta charset="UTF-8">
		<meta name="description" content="mogacko - 8월 18일 모각코">
		<meta property="og:title" content="8월 18일 모각코">
		<meta property="og:description" content="mogacko - 8월 18일 모각코">
		<meta property="og:type" content="website">
		<meta property="og:url" content="team's-blog/코딩황제들/8월-18일-모각코.html">
		<meta property="og:image" content="lib\media\team-blog-코딩황제들-2024-week6.세준1.png">
		<meta property="og:site_name" content="mogacko">
		<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="lib/rss.xml"><script async="" id="webpage-script" src="lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script type="module" async="" id="graph-view-script" src="lib/scripts/graph-view.js"></script><script async="" id="graph-wasm-script" src="lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="tinycolor-script" src="lib/scripts/tinycolor.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="pixi-script" src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.4.0/pixi.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="minisearch-script" src="https://cdn.jsdelivr.net/npm/minisearch@6.3.0/dist/umd/index.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="lib/media/favicon.png"><script async="" id="graph-data-script" src="lib/scripts/graph-data.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-horizontal-spacing:0.6em;--tree-vertical-spacing:0.6em;--sidebar-margin:12px}.sidebar{height:100%;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));font-size:14px;z-index:10;position:relative;overflow:hidden;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}.sidebar-left{left:0}.sidebar-right{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}body.floating-sidebars .sidebar{position:absolute}.sidebar-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .sidebar-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}.sidebar-left .sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}.sidebar-right .sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar:has(.sidebar-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:2em;width:var(--sidebar-width);top:var(--sidebar-margin);padding-inline:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}.sidebar-left .sidebar-topbar{left:0}.sidebar-right .sidebar-topbar{right:0}.topbar-content{overflow:hidden;overflow:clip;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:0!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}.sidebar-left .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}.sidebar-right .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.sidebar-section-header{margin:0 0 1em 0;text-transform:uppercase;letter-spacing:.06em;font-weight:600}body{transition:background-color var(--color-fade-speed) ease-in-out}.webpage-container{display:flex;flex-direction:row;height:100%;width:100%;align-items:stretch;justify-content:center}.document-container{opacity:1;flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0;transition:opacity .2s ease-in-out}.document-container>.markdown-preview-view{margin:var(--sidebar-margin);margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;background-color:var(--background-primary);transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:80vh!important;width:100%!important;max-width:var(--line-width)!important;flex-basis:var(--line-width)!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}.markdown-rendered img:not([width]),.view-content img:not([width]){max-width:100%;outline:0}.document-container>.view-content.embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}.document-container>.view-content.embed>*{max-width:100%;max-height:100%;object-fit:contain}:has(> :is(.math,table)){overflow-x:auto!important}.document-container>.view-content{overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){if("file:"!=location.protocol){let e=document.querySelectorAll("include");for(let t=0;t<e.length;t++){let o=e[t],l=o.getAttribute("src");try{const e=await fetch(l);if(!e.ok){console.log("Could not include file: "+l),o?.remove();continue}let t=await e.text(),n=document.createRange().createContextualFragment(t),i=Array.from(n.children);for(let e of i)e.classList.add("hide"),e.style.transition="opacity 0.5s ease-in-out",setTimeout((()=>{e.classList.remove("hide")}),10);o.before(n),o.remove(),console.log("Included file: "+l)}catch(e){o?.remove(),console.log("Could not include file: "+l,e);continue}}}else{if(document.querySelectorAll("include").length>0){var e=document.createElement("div");e.id="error",e.textContent="Web server exports must be hosted on an http / web server to be viewed correctly.",e.style.position="fixed",e.style.top="50%",e.style.left="50%",e.style.transform="translate(-50%, -50%)",e.style.fontSize="1.5em",e.style.fontWeight="bold",e.style.textAlign="center",document.body.appendChild(e),document.querySelector(".document-container")?.classList.remove("hide")}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script"))),l=0;!function e(){let n=o[l];l++,n&&"true"!=n.getAttribute("loaded")||l<o.length&&e(),l<o.length?n.addEventListener("load",e):t()}()}</script><link rel="stylesheet" href="lib/styles/obsidian.css"><link rel="preload" href="lib/styles/other-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/other-plugins.css"></noscript><link rel="preload" href="lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/main-styles.css"></noscript></head><body class="publish css-settings-manager theme-dark show-inline-title show-ribbon mk-readable-line mk-folder-lines mk-spaces-enabled mk-inline-context-enabled mk-flow-seamless"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="webpage-container workspace"><div class="sidebar-left sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="search-input-container"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..." style="border-radius:10px; border-width: 0px;"><div class="search-input-clear-button" aria-label="Clear search"></div></div><include src="lib/html/file-tree.html"></include></div><script defer="">let ls = document.querySelector(".sidebar-left"); ls.classList.add("is-collapsed"); if (window.innerWidth > 768) ls.classList.remove("is-collapsed"); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div><div class="document-container markdown-reading-view hide"><div class="markdown-preview-view markdown-rendered allow-fold-headings allow-fold-lists is-readable-line-width"><style id="MJX-CHTML-styles">mjx-c.mjx-c1D462.TEX-I::before { padding: 0.442em 0.572em 0.011em 0px; content: "u"; }
mjx-c.mjx-c1D459.TEX-I::before { padding: 0.694em 0.298em 0.011em 0px; content: "l"; }
mjx-c.mjx-c72::before { padding: 0.442em 0.392em 0px 0px; content: "r"; }
mjx-c.mjx-c6E::before { padding: 0.442em 0.556em 0px 0px; content: "n"; }
mjx-c.mjx-c70::before { padding: 0.442em 0.556em 0.194em 0px; content: "p"; }
mjx-c.mjx-c79::before { padding: 0.431em 0.528em 0.204em 0px; content: "y"; }
mjx-c.mjx-c1D450.TEX-I::before { padding: 0.442em 0.433em 0.011em 0px; content: "c"; }
mjx-c.mjx-c42::before { padding: 0.683em 0.708em 0px 0px; content: "B"; }
mjx-c.mjx-c43::before { padding: 0.705em 0.722em 0.021em 0px; content: "C"; }
mjx-c.mjx-c45::before { padding: 0.68em 0.681em 0px 0px; content: "E"; }
mjx-c.mjx-c57::before { padding: 0.683em 1.028em 0.022em 0px; content: "W"; }
mjx-c.mjx-c74::before { padding: 0.615em 0.389em 0.01em 0px; content: "t"; }
mjx-c.mjx-c68::before { padding: 0.694em 0.556em 0px 0px; content: "h"; }
mjx-c.mjx-c4C::before { padding: 0.683em 0.625em 0px 0px; content: "L"; }
mjx-c.mjx-c73::before { padding: 0.448em 0.394em 0.011em 0px; content: "s"; }
mjx-c.mjx-c5B::before { padding: 0.75em 0.278em 0.25em 0px; content: "["; }
mjx-c.mjx-c1D70E.TEX-I::before { padding: 0.431em 0.571em 0.011em 0px; content: "σ"; }
mjx-c.mjx-c5D::before { padding: 0.75em 0.278em 0.25em 0px; content: "]"; }
mjx-munder { display: inline-block; text-align: left; }
mjx-over { text-align: left; }
mjx-munder:not([limits="false"]) { display: inline-table; }
mjx-munder > mjx-row { text-align: left; }
mjx-under { padding-bottom: 0.1em; }
mjx-c.mjx-c2217::before { padding: 0.465em 0.5em 0px 0px; content: "∗"; }
mjx-c.mjx-c1D435.TEX-I::before { padding: 0.683em 0.759em 0px 0px; content: "B"; }
mjx-c.mjx-c1D43A.TEX-I::before { padding: 0.705em 0.786em 0.022em 0px; content: "G"; }
mjx-c.mjx-c1D434.TEX-I::before { padding: 0.716em 0.75em 0px 0px; content: "A"; }
mjx-c.mjx-c1D437.TEX-I::before { padding: 0.683em 0.828em 0px 0px; content: "D"; }
mjx-c.mjx-c200B::before { padding: 0px; content: ""; }
mjx-c.mjx-c61::before { padding: 0.448em 0.5em 0.011em 0px; content: "a"; }
mjx-c.mjx-c78::before { padding: 0.431em 0.528em 0px 0px; content: "x"; }
mjx-c.mjx-c1D706.TEX-I::before { padding: 0.694em 0.583em 0.012em 0px; content: "λ"; }
mjx-c.mjx-c1D703.TEX-I::before { padding: 0.705em 0.469em 0.01em 0px; content: "θ"; }
mjx-c.mjx-c30::before { padding: 0.666em 0.5em 0.022em 0px; content: "0"; }
mjx-c.mjx-c1D465.TEX-I::before { padding: 0.442em 0.572em 0.011em 0px; content: "x"; }
mjx-c.mjx-c1D438.TEX-I::before { padding: 0.68em 0.764em 0px 0px; content: "E"; }
mjx-c.mjx-c2F::before { padding: 0.75em 0.5em 0.25em 0px; content: "/"; }
mjx-c.mjx-c1D447.TEX-I::before { padding: 0.677em 0.704em 0px 0px; content: "T"; }
mjx-c.mjx-c1D44D.TEX-I::before { padding: 0.683em 0.723em 0px 0px; content: "Z"; }
mjx-c.mjx-c1D43F.TEX-I::before { padding: 0.683em 0.681em 0px 0px; content: "L"; }
mjx-c.mjx-c1D441.TEX-I::before { padding: 0.683em 0.888em 0px 0px; content: "N"; }
mjx-c.mjx-c1D457.TEX-I::before { padding: 0.661em 0.412em 0.204em 0px; content: "j"; }
mjx-c.mjx-c1D45D.TEX-I::before { padding: 0.442em 0.503em 0.194em 0px; content: "p"; }
mjx-c.mjx-c1D43B.TEX-I::before { padding: 0.683em 0.888em 0px 0px; content: "H"; }
mjx-c.mjx-c1D444.TEX-I::before { padding: 0.704em 0.791em 0.194em 0px; content: "Q"; }
mjx-c.mjx-c1D45B.TEX-I::before { padding: 0.442em 0.6em 0.011em 0px; content: "n"; }
mjx-c.mjx-c1D45E.TEX-I::before { padding: 0.442em 0.46em 0.194em 0px; content: "q"; }
mjx-munderover { display: inline-block; text-align: left; }
mjx-munderover:not([limits="false"]) { padding-top: 0.1em; }
mjx-munderover:not([limits="false"]) > * { display: block; }
mjx-msubsup { display: inline-block; text-align: left; }
mjx-script { display: inline-block; padding-right: 0.05em; padding-left: 0.033em; }
mjx-script > mjx-spacer { display: block; }
mjx-c.mjx-c32::before { padding: 0.666em 0.5em 0px 0px; content: "2"; }
mjx-c.mjx-c1D458.TEX-I::before { padding: 0.694em 0.521em 0.011em 0px; content: "k"; }
mjx-c.mjx-c2211.TEX-S1::before { padding: 0.75em 1.056em 0.25em 0px; content: "∑"; }
mjx-c.mjx-c22C5::before { padding: 0.31em 0.278em 0px 0px; content: "⋅"; }
mjx-msup { display: inline-block; text-align: left; }
mjx-c.mjx-c1D467.TEX-I::before { padding: 0.442em 0.465em 0.011em 0px; content: "z"; }
mjx-c.mjx-c6C::before { padding: 0.694em 0.278em 0px 0px; content: "l"; }
mjx-c.mjx-c67::before { padding: 0.453em 0.5em 0.206em 0px; content: "g"; }
mjx-c.mjx-c2061::before { padding: 0px; content: ""; }
mjx-c.mjx-c28.TEX-S2::before { padding: 1.15em 0.597em 0.649em 0px; content: "("; }
mjx-c.mjx-c29.TEX-S2::before { padding: 1.15em 0.597em 0.649em 0px; content: ")"; }
mjx-c.mjx-c2C::before { padding: 0.121em 0.278em 0.194em 0px; content: ","; }
mjx-c.mjx-c1D452.TEX-I::before { padding: 0.442em 0.466em 0.011em 0px; content: "e"; }
mjx-c.mjx-c2B::before { padding: 0.583em 0.778em 0.082em 0px; content: "+"; }
mjx-c.mjx-c1D456.TEX-I::before { padding: 0.661em 0.345em 0.011em 0px; content: "i"; }
mjx-c.mjx-c1D454.TEX-I::before { padding: 0.442em 0.477em 0.205em 0px; content: "g"; }
mjx-c.mjx-c1D45A.TEX-I::before { padding: 0.442em 0.878em 0.011em 0px; content: "m"; }
mjx-c.mjx-c65::before { padding: 0.448em 0.444em 0.011em 0px; content: "e"; }
mjx-container[jax="CHTML"] { line-height: 0; }
mjx-container [space="1"] { margin-left: 0.111em; }
mjx-container [space="2"] { margin-left: 0.167em; }
mjx-container [space="3"] { margin-left: 0.222em; }
mjx-container [space="4"] { margin-left: 0.278em; }
mjx-container [space="5"] { margin-left: 0.333em; }
mjx-container [rspace="1"] { margin-right: 0.111em; }
mjx-container [rspace="2"] { margin-right: 0.167em; }
mjx-container [rspace="3"] { margin-right: 0.222em; }
mjx-container [rspace="4"] { margin-right: 0.278em; }
mjx-container [rspace="5"] { margin-right: 0.333em; }
mjx-container [size="s"] { font-size: 70.7%; }
mjx-container [size="ss"] { font-size: 50%; }
mjx-container [size="Tn"] { font-size: 60%; }
mjx-container [size="sm"] { font-size: 85%; }
mjx-container [size="lg"] { font-size: 120%; }
mjx-container [size="Lg"] { font-size: 144%; }
mjx-container [size="LG"] { font-size: 173%; }
mjx-container [size="hg"] { font-size: 207%; }
mjx-container [size="HG"] { font-size: 249%; }
mjx-container [width="full"] { width: 100%; }
mjx-box { display: inline-block; }
mjx-block { display: block; }
mjx-itable { display: inline-table; }
mjx-row { display: table-row; }
mjx-row > * { display: table-cell; }
mjx-mtext { display: inline-block; text-align: left; }
mjx-mstyle { display: inline-block; }
mjx-merror { display: inline-block; color: red; background-color: yellow; }
mjx-mphantom { visibility: hidden; }
mjx-assistive-mml { top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); user-select: none; position: absolute !important; padding: 1px 0px 0px !important; border: 0px !important; display: block !important; width: auto !important; overflow: hidden !important; }
mjx-assistive-mml[display="block"] { width: 100% !important; }
mjx-math { display: inline-block; text-align: left; line-height: 0; text-indent: 0px; font-style: normal; font-weight: normal; font-size: 100%; letter-spacing: normal; border-collapse: collapse; overflow-wrap: normal; word-spacing: normal; white-space: nowrap; direction: ltr; padding: 1px 0px; }
mjx-container[jax="CHTML"][display="true"] { display: block; text-align: center; margin: 1em 0px; }
mjx-container[jax="CHTML"][display="true"][width="full"] { display: flex; }
mjx-container[jax="CHTML"][display="true"] mjx-math { padding: 0px; }
mjx-container[jax="CHTML"][justify="left"] { text-align: left; }
mjx-container[jax="CHTML"][justify="right"] { text-align: right; }
mjx-mi { display: inline-block; text-align: left; }
mjx-c { display: inline-block; }
mjx-utext { display: inline-block; padding: 0.75em 0px 0.2em; }
mjx-mo { display: inline-block; text-align: left; }
mjx-stretchy-h { display: inline-table; width: 100%; }
mjx-stretchy-h > * { display: table-cell; width: 0px; }
mjx-stretchy-h > * > mjx-c { display: inline-block; transform: scaleX(1); }
mjx-stretchy-h > * > mjx-c::before { display: inline-block; width: initial; }
mjx-stretchy-h > mjx-ext { overflow: clip visible; width: 100%; }
mjx-stretchy-h > mjx-ext > mjx-c::before { transform: scaleX(500); }
mjx-stretchy-h > mjx-ext > mjx-c { width: 0px; }
mjx-stretchy-h > mjx-beg > mjx-c { margin-right: -0.1em; }
mjx-stretchy-h > mjx-end > mjx-c { margin-left: -0.1em; }
mjx-stretchy-v { display: inline-block; }
mjx-stretchy-v > * { display: block; }
mjx-stretchy-v > mjx-beg { height: 0px; }
mjx-stretchy-v > mjx-end > mjx-c { display: block; }
mjx-stretchy-v > * > mjx-c { transform: scaleY(1); transform-origin: left center; overflow: hidden; }
mjx-stretchy-v > mjx-ext { display: block; height: 100%; box-sizing: border-box; border: 0px solid transparent; overflow: visible clip; }
mjx-stretchy-v > mjx-ext > mjx-c::before { width: initial; box-sizing: border-box; }
mjx-stretchy-v > mjx-ext > mjx-c { transform: scaleY(500) translateY(0.075em); overflow: visible; }
mjx-mark { display: inline-block; height: 0px; }
mjx-mfrac { display: inline-block; text-align: left; }
mjx-frac { display: inline-block; vertical-align: 0.17em; padding: 0px 0.22em; }
mjx-frac[type="d"] { vertical-align: 0.04em; }
mjx-frac[delims] { padding: 0px 0.1em; }
mjx-frac[atop] { padding: 0px 0.12em; }
mjx-frac[atop][delims] { padding: 0px; }
mjx-dtable { display: inline-table; width: 100%; }
mjx-dtable > * { font-size: 2000%; }
mjx-dbox { display: block; font-size: 5%; }
mjx-num { display: block; text-align: center; }
mjx-den { display: block; text-align: center; }
mjx-mfrac[bevelled] > mjx-num { display: inline-block; }
mjx-mfrac[bevelled] > mjx-den { display: inline-block; }
mjx-den[align="right"], mjx-num[align="right"] { text-align: right; }
mjx-den[align="left"], mjx-num[align="left"] { text-align: left; }
mjx-nstrut { display: inline-block; height: 0.054em; width: 0px; vertical-align: -0.054em; }
mjx-nstrut[type="d"] { height: 0.217em; vertical-align: -0.217em; }
mjx-dstrut { display: inline-block; height: 0.505em; width: 0px; }
mjx-dstrut[type="d"] { height: 0.726em; }
mjx-line { display: block; box-sizing: border-box; min-height: 1px; height: 0.06em; border-top: 0.06em solid; margin: 0.06em -0.1em; overflow: hidden; }
mjx-line[type="d"] { margin: 0.18em -0.1em; }
mjx-mrow { display: inline-block; text-align: left; }
mjx-mn { display: inline-block; text-align: left; }
mjx-msub { display: inline-block; text-align: left; }
mjx-texatom { display: inline-block; text-align: left; }
mjx-c::before { display: block; width: 0px; }
.MJX-TEX { font-family: MJXZERO, MJXTEX; }
.TEX-B { font-family: MJXZERO, MJXTEX-B; }
.TEX-I { font-family: MJXZERO, MJXTEX-I; }
.TEX-MI { font-family: MJXZERO, MJXTEX-MI; }
.TEX-BI { font-family: MJXZERO, MJXTEX-BI; }
.TEX-S1 { font-family: MJXZERO, MJXTEX-S1; }
.TEX-S2 { font-family: MJXZERO, MJXTEX-S2; }
.TEX-S3 { font-family: MJXZERO, MJXTEX-S3; }
.TEX-S4 { font-family: MJXZERO, MJXTEX-S4; }
.TEX-A { font-family: MJXZERO, MJXTEX-A; }
.TEX-C { font-family: MJXZERO, MJXTEX-C; }
.TEX-CB { font-family: MJXZERO, MJXTEX-CB; }
.TEX-FR { font-family: MJXZERO, MJXTEX-FR; }
.TEX-FRB { font-family: MJXZERO, MJXTEX-FRB; }
.TEX-SS { font-family: MJXZERO, MJXTEX-SS; }
.TEX-SSB { font-family: MJXZERO, MJXTEX-SSB; }
.TEX-SSI { font-family: MJXZERO, MJXTEX-SSI; }
.TEX-SC { font-family: MJXZERO, MJXTEX-SC; }
.TEX-T { font-family: MJXZERO, MJXTEX-T; }
.TEX-V { font-family: MJXZERO, MJXTEX-V; }
.TEX-VB { font-family: MJXZERO, MJXTEX-VB; }
mjx-stretchy-v mjx-c, mjx-stretchy-h mjx-c { font-family: MJXZERO, MJXTEX-S1, MJXTEX-S4, MJXTEX, MJXTEX-A !important; }
@font-face { font-family: MJXZERO; src: url("lib/fonts/mathjax_zero.woff") format("woff"); }
@font-face { font-family: MJXTEX; src: url("lib/fonts/mathjax_main-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-B; src: url("lib/fonts/mathjax_main-bold.woff") format("woff"); }
@font-face { font-family: MJXTEX-I; src: url("lib/fonts/mathjax_math-italic.woff") format("woff"); }
@font-face { font-family: MJXTEX-MI; src: url("lib/fonts/mathjax_main-italic.woff") format("woff"); }
@font-face { font-family: MJXTEX-BI; src: url("lib/fonts/mathjax_math-bolditalic.woff") format("woff"); }
@font-face { font-family: MJXTEX-S1; src: url("lib/fonts/mathjax_size1-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-S2; src: url("lib/fonts/mathjax_size2-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-S3; src: url("lib/fonts/mathjax_size3-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-S4; src: url("lib/fonts/mathjax_size4-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-A; src: url("lib/fonts/mathjax_ams-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-C; src: url("lib/fonts/mathjax_calligraphic-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-CB; src: url("lib/fonts/mathjax_calligraphic-bold.woff") format("woff"); }
@font-face { font-family: MJXTEX-FR; src: url("lib/fonts/mathjax_fraktur-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-FRB; src: url("lib/fonts/mathjax_fraktur-bold.woff") format("woff"); }
@font-face { font-family: MJXTEX-SS; src: url("lib/fonts/mathjax_sansserif-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-SSB; src: url("lib/fonts/mathjax_sansserif-bold.woff") format("woff"); }
@font-face { font-family: MJXTEX-SSI; src: url("lib/fonts/mathjax_sansserif-italic.woff") format("woff"); }
@font-face { font-family: MJXTEX-SC; src: url("lib/fonts/mathjax_script-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-T; src: url("lib/fonts/mathjax_typewriter-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-V; src: url("lib/fonts/mathjax_vector-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-VB; src: url("lib/fonts/mathjax_vector-bold.woff") format("woff"); }
mjx-c.mjx-c1D45C.TEX-I::before { padding: 0.441em 0.485em 0.011em 0px; content: "o"; }
mjx-c.mjx-c1D451.TEX-I::before { padding: 0.694em 0.52em 0.01em 0px; content: "d"; }
mjx-c.mjx-c1D460.TEX-I::before { padding: 0.442em 0.469em 0.01em 0px; content: "s"; }
mjx-c.mjx-cA0::before { padding: 0px 0.25em 0px 0px; content: " "; }
mjx-c.mjx-c3D::before { padding: 0.583em 0.778em 0.082em 0px; content: "="; }
mjx-c.mjx-c1D466.TEX-I::before { padding: 0.442em 0.49em 0.205em 0px; content: "y"; }
mjx-c.mjx-c31::before { padding: 0.666em 0.5em 0px 0px; content: "1"; }
mjx-c.mjx-c2212::before { padding: 0.583em 0.778em 0.082em 0px; content: "−"; }
mjx-c.mjx-c1D443.TEX-I::before { padding: 0.683em 0.751em 0px 0px; content: "P"; }
mjx-c.mjx-c28::before { padding: 0.75em 0.389em 0.25em 0px; content: "("; }
mjx-c.mjx-c5C::before { padding: 0.75em 0.5em 0.25em 0px; content: "\\"; }
mjx-c.mjx-c63::before { padding: 0.448em 0.444em 0.011em 0px; content: "c"; }
mjx-c.mjx-c6F::before { padding: 0.448em 0.5em 0.01em 0px; content: "o"; }
mjx-c.mjx-c6D::before { padding: 0.442em 0.833em 0px 0px; content: "m"; }
mjx-c.mjx-c62::before { padding: 0.694em 0.556em 0.011em 0px; content: "b"; }
mjx-c.mjx-c69::before { padding: 0.669em 0.278em 0px 0px; content: "i"; }
mjx-c.mjx-c1D436.TEX-I::before { padding: 0.705em 0.76em 0.022em 0px; content: "C"; }
mjx-c.mjx-c2223::before { padding: 0.75em 0.278em 0.249em 0px; content: "∣"; }
mjx-c.mjx-c1D44B.TEX-I::before { padding: 0.683em 0.852em 0px 0px; content: "X"; }
mjx-c.mjx-c29::before { padding: 0.75em 0.389em 0.25em 0px; content: ")"; }
</style><div class="markdown-preview-sizer markdown-preview-section"><h1 class="page-title heading inline-title" id="계획"><p dir="auto">계획</p></h1><div class="heading-wrapper"><div class="heading-children"><div><p dir="auto">energy-based model, 특히 energy-based GAN에 대해 알아보기 및 대조학습코드 구현 </p></div><div><p dir="auto"><strong>회의방법</strong><br>
온라인(naver whale on) *zoom은 40분이상하려면 유료로 결제를 해야하기 때문에 whale on을 활용했습니다. </p></div><div><p dir="auto"><strong>팀원 블로그</strong><br>
박세준 <a rel="noopener" class="external-link" href="https://kepler-dev-3141.github.io/" target="_blank">https://kepler-dev-3141.github.io/</a><br>
신우석 <a rel="noopener" class="external-link" href="https://blog.naver.com/sws040201/" target="_blank">https://blog.naver.com/sws040201/</a><br>
김채연 <a rel="noopener" class="external-link" href="https://kcyeon0127.github.io/" target="_blank">https://kcyeon0127.github.io/</a></p></div><div><p dir="auto"><strong>ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ--------</strong></p></div></div></div><div class="heading-wrapper"><h1 data-heading="결과" dir="auto" class="heading" id="결과">결과</h1><div class="heading-children"><div class="heading-wrapper"><h2 data-heading="준혁(팀장)" dir="auto" class="heading" id="준혁(팀장)"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>준혁(팀장)</h2><div class="heading-children"><div class="heading-wrapper"><h3 data-heading="목표:" dir="auto" class="heading" id="목표:"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>목표:</h3><div class="heading-children"><div><p dir="auto">에너지 기반 GAN(Energy-Based Generative Adversarial Network, EBGAN)에 대해 알아본다.</p></div></div></div><div class="heading-wrapper"><h3 data-heading="결과:" dir="auto" class="heading" id="결과:"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>결과:</h3><div class="heading-children"><div class="heading-wrapper"><h4 data-heading="1. EBGAN이란?" dir="auto" class="heading" id="1._EBGAN이란?"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>1. EBGAN이란?</h4><div class="heading-children"><div><p dir="auto">*전통적인 GAN모델의 변형으로, 에너지 기반 모델(EBM)의 개념을 도입하여 GAN의 판별자(Discriminator)를 재설계한 모델입니다. EBGAN은 전통적인 GAN보다 더 안정적이고 유연한 학습을 가능하게 하기 위해 제안되었습니다.</p></div></div></div><div class="heading-wrapper"><h4 data-heading="2. **전통적인 GAN의 기본 개념**" dir="auto" class="heading" id="2._**전통적인_GAN의_기본_개념**"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>2. <strong>전통적인 GAN의 기본 개념</strong></h4><div class="heading-children"><div><ul>
<li data-line="0" dir="auto"><strong>생성자(Generator):</strong> 랜덤한 노이즈 벡터를 입력으로 받아, 이로부터 현실적인 데이터를 생성하는 네트워크입니다.</li>
<li data-line="1" dir="auto"><strong>판별자(Discriminator):</strong> 입력 데이터가 실제(real) 데이터인지 생성된(fake) 데이터인지 구분하는 네트워크입니다.</li>
<li data-line="2" dir="auto">GAN의 목표는 생성자가 점점 더 현실적인 데이터를 생성하도록 학습하는 것입니다. 생성자가 만든 데이터가 실제 데이터를 닮아가면서, 판별자는 점점 더 어려운 구별 문제를 해결해야 하므로 두 네트워크가 서로 경쟁하면서 발전합니다.</li>
</ul></div></div></div><div class="heading-wrapper"><h4 data-heading="3. **EBGAN에서의 변화**" dir="auto" class="heading" id="3._**EBGAN에서의_변화**"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>3. <strong>EBGAN에서의 변화</strong></h4><div class="heading-children"><div><ul>
<li data-line="0" dir="auto"><strong>에너지 기반 판별자:</strong> EBGAN에서 판별자는 단순히 이진 분류를 수행하는 대신, 데이터를 입력받아 그 데이터의 "에너지"를 계산합니다. 이 에너지는 데이터가 얼마나 "현실적인지"를 나타내며, EBM에서 사용되는 에너지 함수와 유사한 역할을 합니다.</li>
<li data-line="1" dir="auto"><strong>목표:</strong> EBGAN의 목표는 생성된 데이터에 높은 에너지를, 실제 데이터에 낮은 에너지를 할당하는 것입니다.</li>
</ul></div></div></div><div class="heading-wrapper"><h4 data-heading="4. **EBGAN의 작동 방식**" dir="auto" class="heading" id="4._**EBGAN의_작동_방식**"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>4. <strong>EBGAN의 작동 방식</strong></h4><div class="heading-children"><div><ul>
<li data-line="0" dir="auto"><strong>판별자의 역할:</strong> EBGAN에서 판별자는 입력 데이터 xxx에 대해 에너지 값 E(x)E(x)E(x)를 계산합니다. 이 에너지는 데이터가 실제에 가까울수록 낮게, 비현실적일수록 높게 설정됩니다.</li>
<li data-line="1" dir="auto"><strong>생성자의 역할:</strong> 생성자는 낮은 에너지를 가진 데이터를 생성하도록 학습합니다. 즉, 판별자가 낮은 에너지를 할당하는 데이터를 생성하려고 시도합니다.</li>
<li data-line="2" dir="auto"><strong>손실 함수:</strong> EBGAN의 손실 함수는 전통적인 GAN과 다르게, 판별자가 계산한 에너지 값을 최소화하거나 최대화하는 방식으로 정의됩니다.</li>
</ul></div></div></div><div class="heading-wrapper"><h4 data-heading="5. **EBGAN의 장점**" dir="auto" class="heading" id="5._**EBGAN의_장점**"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>5. <strong>EBGAN의 장점</strong></h4><div class="heading-children"><div><ul>
<li data-line="0" dir="auto"><strong>학습의 안정성:</strong> 전통적인 GAN에서는 종종 학습이 불안정해지거나 모드 붕괴(mode collapse)가 발생할 수 있습니다. EBGAN은 에너지 기반 접근 방식을 통해 이러한 문제를 완화할 수 있습니다.</li>
<li data-line="1" dir="auto"><strong>유연성:</strong> 판별자가 에너지를 계산하는 방식은 단순한 이진 분류보다 더 유연하여, 다양한 형태의 손실 함수나 학습 전략을 적용할 수 있습니다.</li>
</ul></div></div></div><div class="heading-wrapper"><h4 data-heading="6. **예시**" dir="auto" class="heading" id="6._**예시**"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>6. <strong>예시</strong></h4><div class="heading-children"><div><ul>
<li data-line="0" dir="auto">예를 들어, 이미지 생성 문제에서 EBGAN은 판별자가 이미지에 대해 "에너지"를 계산하고, 생성자는 이 에너지를 낮추는 방향으로 이미지를 생성합니다. 결과적으로, 생성된 이미지는 더 현실적이고, 판별자는 더 까다로운 기준으로 이미지를 평가하게 됩니다.</li>
</ul></div></div></div><div class="heading-wrapper"><h4 data-heading="7. **EBGAN의 응용**" dir="auto" class="heading" id="7._**EBGAN의_응용**"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>7. <strong>EBGAN의 응용</strong></h4><div class="heading-children"><div><ul>
<li data-line="0" dir="auto"><strong>이미지 생성:</strong> 현실적인 이미지를 생성하는 데 사용할 수 있습니다. 특히, 고해상도 이미지 생성이나 다양한 스타일의 이미지 생성에 효과적일 수 있습니다.</li>
<li data-line="1" dir="auto"><strong>비디오 생성:</strong> 비디오의 연속적인 프레임을 생성할 때, 각 프레임이 이전 프레임과의 연속성을 가지면서도 개별적으로 현실적인 에너지를 가지도록 학습할 수 있습니다.</li>
<li data-line="2" dir="auto"><strong>자연어 처리:</strong> 텍스트 생성에서도 EBGAN을 응용하여 더 자연스러운 문장을 생성하는 데 사용될 수 있습니다.</li>
</ul></div><div><p dir="auto"><strong>ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ--------</strong></p></div></div></div></div></div></div></div><div class="heading-wrapper"><h2 data-heading="세준" dir="auto" class="heading" id="세준"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>세준</h2><div class="heading-children"><div class="heading-wrapper"><h3 data-heading="목표:" dir="auto" class="heading" id="목표:"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>목표:</h3><div class="heading-children"><div><p dir="auto">저번에 구현해 본 EBGAN이 왜 잘 되지 않았는지 분석하기</p></div></div></div><div class="heading-wrapper"><h3 data-heading="결과:" dir="auto" class="heading" id="결과:"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>결과:</h3><div class="heading-children"><div><p dir="auto">Github에서 EBGAN이 구현된 코드를 실행해보고 내가 구현한 코드와 어떻게 다른지 분석해보기로 하였다.<br>
<a rel="noopener" class="external-link" href="https://github.com/znxlwm/pytorch-generative-model-collections" target="_blank">https://github.com/znxlwm/pytorch-generative-model-collections</a><br>
Github에 있는 코드는 Colab에서 작동되도록 구현되지 않았고 결과를 실시간으로 볼 수 없어서 코드를 수정하였다.</p></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded"><span class="token keyword">import</span> torch<span class="token punctuation">,</span> time<span class="token punctuation">,</span> os<span class="token punctuation">,</span> pickle
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms
<span class="token keyword">import</span> imageio
<span class="token keyword">import</span> gzip
<span class="token keyword">import</span> scipy<span class="token punctuation">.</span>misc
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
</code><button class="copy-code-button">Copy</button></pre></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded"><span class="token keyword">from</span> google<span class="token punctuation">.</span>colab <span class="token keyword">import</span> drive
drive<span class="token punctuation">.</span>mount<span class="token punctuation">(</span><span class="token string">'/content/drive'</span><span class="token punctuation">)</span>
</code><button class="copy-code-button">Copy</button></pre></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded"><span class="token keyword">def</span> <span class="token function">print_network</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_params <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        num_params <span class="token operator">+=</span> param<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Total number of parameters: %d'</span> <span class="token operator">%</span> num_params<span class="token punctuation">)</span>
  
<span class="token keyword">def</span> <span class="token function">initialize_weights</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> m <span class="token keyword">in</span> net<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
            m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>
            m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
            m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>
            m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
            m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>
            m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">dataloader</span><span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Grayscale<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> input_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    data_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>
        datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">'data/mnist'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span><span class="token punctuation">,</span>
        batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  
    <span class="token keyword">return</span> data_loader
</code><button class="copy-code-button">Copy</button></pre></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded"><span class="token keyword">class</span> <span class="token class-name">generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)</span>
    <span class="token comment"># Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> input_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_dim <span class="token operator">=</span> input_dim
        self<span class="token punctuation">.</span>output_dim <span class="token operator">=</span> output_dim
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
  
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_dim<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">128</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">128</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>output_dim<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        initialize_weights<span class="token punctuation">(</span>self<span class="token punctuation">)</span>
  
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>deconv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
  
        <span class="token keyword">return</span> x
</code><button class="copy-code-button">Copy</button></pre></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded"><span class="token keyword">class</span> <span class="token class-name">discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># It must be Auto-Encoder style architecture</span>
    <span class="token comment"># Architecture : (64)4c2s-FC32-FC64*14*14_BR-(1)4dc2s_S</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> input_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_dim <span class="token operator">=</span> input_dim
        self<span class="token punctuation">.</span>output_dim <span class="token operator">=</span> output_dim
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
  
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_dim<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>code <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># bn and relu are excluded since code is used in pullaway_loss</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>output_dim<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment"># nn.Sigmoid(),</span>
        <span class="token punctuation">)</span>
        initialize_weights<span class="token punctuation">(</span>self<span class="token punctuation">)</span>
  
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        code <span class="token operator">=</span> self<span class="token punctuation">.</span>code<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>code<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>deconv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
  
        <span class="token keyword">return</span> x<span class="token punctuation">,</span> code
</code><button class="copy-code-button">Copy</button></pre></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded"><span class="token keyword">class</span> <span class="token class-name">EBGAN</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># parameters</span>
        self<span class="token punctuation">.</span>epoch <span class="token operator">=</span> <span class="token number">50</span>
        self<span class="token punctuation">.</span>sample_num <span class="token operator">=</span> <span class="token number">100</span>
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> <span class="token number">64</span>
        self<span class="token punctuation">.</span>save_dir <span class="token operator">=</span> <span class="token string">'/content/drive/MyDrive/EBGAN/model/'</span>
        self<span class="token punctuation">.</span>result_dir <span class="token operator">=</span> <span class="token string">'/content/drive/MyDrive/EBGAN/res/'</span>
        self<span class="token punctuation">.</span>log_dir <span class="token operator">=</span> <span class="token string">'/content/drive/MyDrive/EBGAN/log/'</span>
        self<span class="token punctuation">.</span>gpu_mode <span class="token operator">=</span> <span class="token boolean">True</span>
        self<span class="token punctuation">.</span>model_name <span class="token operator">=</span> <span class="token string">'EBGAN'</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> <span class="token number">28</span>
        self<span class="token punctuation">.</span>z_dim <span class="token operator">=</span> <span class="token number">62</span>
        self<span class="token punctuation">.</span>pt_loss_weight <span class="token operator">=</span> <span class="token number">0.1</span>
        self<span class="token punctuation">.</span>margin <span class="token operator">=</span> <span class="token number">1</span>
        self<span class="token punctuation">.</span>dataset <span class="token operator">=</span> <span class="token string">'mnist'</span>
  
        self<span class="token punctuation">.</span>lrG <span class="token operator">=</span> <span class="token number">0.0002</span>
        self<span class="token punctuation">.</span>lrD <span class="token operator">=</span> <span class="token number">0.0002</span>
        self<span class="token punctuation">.</span>beta1 <span class="token operator">=</span> <span class="token number">0.5</span>
        self<span class="token punctuation">.</span>beta2 <span class="token operator">=</span> <span class="token number">0.999</span>
  
        <span class="token comment"># load dataset</span>
        self<span class="token punctuation">.</span>data_loader <span class="token operator">=</span> dataloader<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        data <span class="token operator">=</span> self<span class="token punctuation">.</span>data_loader<span class="token punctuation">.</span>__iter__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__next__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
  
        <span class="token comment"># networks init</span>
        self<span class="token punctuation">.</span>G <span class="token operator">=</span> generator<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>self<span class="token punctuation">.</span>z_dim<span class="token punctuation">,</span> output_dim<span class="token operator">=</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_size<span class="token operator">=</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>D <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> output_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> input_size<span class="token operator">=</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>G_optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>G<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>self<span class="token punctuation">.</span>lrG<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>beta1<span class="token punctuation">,</span> self<span class="token punctuation">.</span>beta2<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>D_optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>D<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>self<span class="token punctuation">.</span>lrD<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>beta1<span class="token punctuation">,</span> self<span class="token punctuation">.</span>beta2<span class="token punctuation">)</span><span class="token punctuation">)</span>
  
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>gpu_mode<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>G<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>D<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>MSE_loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>MSE_loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
  
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'---------- Networks architecture -------------'</span><span class="token punctuation">)</span>
        print_network<span class="token punctuation">(</span>self<span class="token punctuation">.</span>G<span class="token punctuation">)</span>
        print_network<span class="token punctuation">(</span>self<span class="token punctuation">.</span>D<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-----------------------------------------------'</span><span class="token punctuation">)</span>
  
        <span class="token comment"># fixed noise</span>
        self<span class="token punctuation">.</span>sample_z_ <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>gpu_mode<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>sample_z_ <span class="token operator">=</span> self<span class="token punctuation">.</span>sample_z_<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
  
    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>train_hist <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>train_hist<span class="token punctuation">[</span><span class="token string">'D_loss'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>train_hist<span class="token punctuation">[</span><span class="token string">'G_loss'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>train_hist<span class="token punctuation">[</span><span class="token string">'per_epoch_time'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>train_hist<span class="token punctuation">[</span><span class="token string">'total_time'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
  
        self<span class="token punctuation">.</span>y_real_<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_fake_ <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>gpu_mode<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>y_real_<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_fake_ <span class="token operator">=</span> self<span class="token punctuation">.</span>y_real_<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_fake_<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
  
        self<span class="token punctuation">.</span>D<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'training start!!'</span><span class="token punctuation">)</span>
        start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>G<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
            epoch_start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> <span class="token builtin">iter</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> <span class="token builtin">iter</span> <span class="token operator">==</span> self<span class="token punctuation">.</span>data_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">:</span>
                    <span class="token keyword">break</span>
  
                z_ <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> self<span class="token punctuation">.</span>gpu_mode<span class="token punctuation">:</span>
                    x_<span class="token punctuation">,</span> z_ <span class="token operator">=</span> x_<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> z_<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
  
                <span class="token comment"># update D network</span>
                self<span class="token punctuation">.</span>D_optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
  
                D_real<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>D<span class="token punctuation">(</span>x_<span class="token punctuation">)</span>
                D_real_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>MSE_loss<span class="token punctuation">(</span>D_real<span class="token punctuation">,</span> x_<span class="token punctuation">)</span>
  
                G_ <span class="token operator">=</span> self<span class="token punctuation">.</span>G<span class="token punctuation">(</span>z_<span class="token punctuation">)</span>
                D_fake<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>D<span class="token punctuation">(</span>G_<span class="token punctuation">)</span>
                D_fake_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>MSE_loss<span class="token punctuation">(</span>D_fake<span class="token punctuation">,</span> G_<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  
                D_loss <span class="token operator">=</span> D_real_loss <span class="token operator">+</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>margin <span class="token operator">-</span> D_fake_loss<span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>train_hist<span class="token punctuation">[</span><span class="token string">'D_loss'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>D_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  
                D_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>D_optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
  
                <span class="token comment"># update G network</span>
                self<span class="token punctuation">.</span>G_optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

                G_ <span class="token operator">=</span> self<span class="token punctuation">.</span>G<span class="token punctuation">(</span>z_<span class="token punctuation">)</span>
                D_fake<span class="token punctuation">,</span> D_fake_code <span class="token operator">=</span> self<span class="token punctuation">.</span>D<span class="token punctuation">(</span>G_<span class="token punctuation">)</span>
                D_fake_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>MSE_loss<span class="token punctuation">(</span>D_fake<span class="token punctuation">,</span> G_<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                G_loss <span class="token operator">=</span> D_fake_loss <span class="token operator">+</span> self<span class="token punctuation">.</span>pt_loss_weight <span class="token operator">*</span> self<span class="token punctuation">.</span>pullaway_loss<span class="token punctuation">(</span>D_fake_code<span class="token punctuation">.</span>view<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>train_hist<span class="token punctuation">[</span><span class="token string">'G_loss'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>G_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  
                G_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>G_optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
  
                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">iter</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f"</span> <span class="token operator">%</span>
                          <span class="token punctuation">(</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">iter</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>data_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> D_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> G_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  
            self<span class="token punctuation">.</span>train_hist<span class="token punctuation">[</span><span class="token string">'per_epoch_time'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> epoch_start_time<span class="token punctuation">)</span>
            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>visualize_results<span class="token punctuation">(</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  
        self<span class="token punctuation">.</span>train_hist<span class="token punctuation">[</span><span class="token string">'total_time'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Avg one epoch time: %.2f, total %d epochs time: %.2f"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>self<span class="token punctuation">.</span>train_hist<span class="token punctuation">[</span><span class="token string">'per_epoch_time'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              self<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> self<span class="token punctuation">.</span>train_hist<span class="token punctuation">[</span><span class="token string">'total_time'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  
    <span class="token keyword">def</span> <span class="token function">pullaway_loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">""" pullaway_loss tensorflow version code
  
            norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))
            normalized_embeddings = embeddings / norm
            similarity = tf.matmul(
                normalized_embeddings, normalized_embeddings, transpose_b=True)
            batch_size = tf.cast(tf.shape(embeddings)[0], tf.float32)
            pt_loss = (tf.reduce_sum(similarity) - batch_size) / (batch_size * (batch_size - 1))
            return pt_loss
  
        """</span>
        <span class="token comment"># norm = torch.sqrt(torch.sum(embeddings ** 2, 1, keepdim=True))</span>
        <span class="token comment"># normalized_embeddings = embeddings / norm</span>
        <span class="token comment"># similarity = torch.matmul(normalized_embeddings, normalized_embeddings.transpose(1, 0))</span>
        <span class="token comment"># batch_size = embeddings.size()[0]</span>
        <span class="token comment"># pt_loss = (torch.sum(similarity) - batch_size) / (batch_size * (batch_size - 1))</span>
  
        norm <span class="token operator">=</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>embeddings<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        normalized_embeddings <span class="token operator">=</span> embeddings <span class="token operator">/</span> norm
        similarity <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>normalized_embeddings<span class="token punctuation">,</span> normalized_embeddings<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>
        batch_size <span class="token operator">=</span> embeddings<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        pt_loss <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>similarity<span class="token punctuation">)</span> <span class="token operator">-</span> batch_size<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>batch_size <span class="token operator">*</span> <span class="token punctuation">(</span>batch_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  
        <span class="token keyword">return</span> pt_loss
  
  
    <span class="token keyword">def</span> <span class="token function">visualize_results</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epoch<span class="token punctuation">,</span> fix<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        gen_data_plot <span class="token operator">=</span> self<span class="token punctuation">.</span>G<span class="token punctuation">(</span>self<span class="token punctuation">.</span>sample_z_<span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
        fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        fig<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Generated Images After </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token punctuation">}</span></span><span class="token string"> Epochs"</span></span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>gen_data_plot<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">"gray_r"</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code><button class="copy-code-button">Copy</button></pre></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded">gan <span class="token operator">=</span> EBGAN<span class="token punctuation">(</span><span class="token punctuation">)</span>
gan<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code><button class="copy-code-button">Copy</button></pre></div><div><p dir="auto">Github에 있는 코드를 실행한 경우 아래와 같이 결과가 잘 나왔다. 50번째 Epoch의 결과이다.</p></div><div><p dir="auto"><span alt="team-blog-코딩황제들-2024-week6.세준1.png" src="team-blog-코딩황제들-2024-week6.세준1.png" class="internal-embed media-embed image-embed is-loaded"><img alt="team-blog-코딩황제들-2024-week6.세준1.png" src="lib/media/team-blog-코딩황제들-2024-week6.세준1.png"></span></p></div><div><p dir="auto">저번에 내가 짠 코드와 어떤 부분이 다른지 비교해본 결과 network를 업데이트 하는 부분에서는 차이가 거의 없었다. Generator의 Loss를 구할 때 PT를 계산하여 과적합을 막는 부분에서 차이가 있었지만 이 부분은 제거하고 테스트 해 본 결과 이 부분 때문에 문제가 생긴 것 같지는 않았다. 모델을 설계하는 부분에서 차이가 있었다. 이 부분을 좀 더 공부해 봐야 할 것 같다.</p></div><div><p dir="auto"><strong>ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ--------</strong></p></div></div></div></div></div><div class="heading-wrapper"><h2 data-heading="우석" dir="auto" class="heading" id="우석"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>우석</h2><div class="heading-children"><div class="heading-wrapper"><h3 data-heading="목표:" dir="auto" class="heading" id="목표:"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>목표:</h3><div class="heading-children"><div><p dir="auto">EBGAN을 이해하고 코드를 돌려본다.</p></div></div></div><div class="heading-wrapper"><h3 data-heading="결과:" dir="auto" class="heading" id="결과:"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>결과:</h3><div class="heading-children"><div><p dir="auto">EBGAN의 loss를 구하는 식을 알게 되었다.</p></div><div class="heading-wrapper"><h4 data-heading="판별자의 손실 함수" dir="auto" class="heading" id="판별자의_손실_함수"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>판별자의 손실 함수</h4><div class="heading-children"><div><p dir="auto"><span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.309em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c200B"></mjx-c></mjx-mo></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.153em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c200B"></mjx-c></mjx-mo></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.153em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c200B"></mjx-c></mjx-mo></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D467 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math></mjx-container></span></p></div><div><p dir="auto"><strong>DAE​(x)</strong>: 입력 데이터 x에 대해 Autoencoder 기반 판별자가 계산한 에너지 또는 손실이다.</p></div><div><p dir="auto"><strong>DAE​(G(z))</strong>: 생성된 데이터 G(z)에 대해 Autoencoder 기반 판별자가 계산한 에너지 또는 손실이다.</p></div><div><p dir="auto"><strong>m</strong>: 마진(margin) 값으로, 에너지 기반 판별자의 판단을 더 명확하게 만들어주는 임계값이다. 판별자가 원본 데이터와 생성된 데이터의 에너지를 구분하는 데 사용된다.</p></div><div><p dir="auto"><strong>max(0,m−DAE​(G(z)))</strong>: 생성된 데이터의 에너지가 마진 m보다 낮을 때만 손실에 기여하게 하며, 이를 통해 판별자가 생성된 데이터를 구분하도록 유도한다.</p></div><div><p dir="auto">​</p></div></div></div><div class="heading-wrapper"><h4 data-heading="생성자의 손실 함수" dir="auto" class="heading" id="생성자의_손실_함수"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>생성자의 손실 함수</h4><div class="heading-children"><div><p dir="auto"><span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.325em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D43A TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c200B"></mjx-c></mjx-mo></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.153em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c200B"></mjx-c></mjx-mo></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D467 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D706 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-math></mjx-container></span></p></div><div><p dir="auto"><strong>DAE​(G(z))</strong>: 생성자가 생성한 데이터 G(z)에 대한 판별자의 에너지이다. 생성자는 이 에너지를 최소화하려고 시도한다.</p></div><div><p dir="auto"><strong>λ⋅PT</strong>: 여기서 PT는 Pulling Term으로, 생성된 데이터 분포가 실제 데이터 분포와 유사하게 만들기 위한 추가적인 제약이나 규제이다.</p></div><div><p dir="auto">λ는 이 항목의 중요성을 조정하는 하이퍼파라미터이다.</p></div><div><p dir="auto">​<br>
<strong>[출처]</strong> <a data-tooltip-position="top" aria-label="https://blog.naver.com/sws040201/223553540153" rel="noopener" class="external-link" href="https://blog.naver.com/sws040201/223553540153" target="_blank">EBM (8/18)</a>|<strong>작성자</strong> <a data-tooltip-position="top" aria-label="https://blog.naver.com/sws040201" rel="noopener" class="external-link" href="https://blog.naver.com/sws040201" target="_blank">sws040201</a></p></div><div><p dir="auto"><strong>ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ--------</strong></p></div></div></div></div></div></div></div><div class="heading-wrapper"><h2 data-heading="채연" dir="auto" class="heading" id="채연"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>채연</h2><div class="heading-children"><div class="heading-wrapper"><h3 data-heading="목표:" dir="auto" class="heading" id="목표:"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>목표:</h3><div class="heading-children"><div><p dir="auto">대조학습코드를 구현해본다.</p></div></div></div><div class="heading-wrapper"><h3 data-heading="결과:" dir="auto" class="heading" id="결과:"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>결과:</h3><div class="heading-children"><div><p dir="auto">대조 학습에서 주로 사용되는 방식 중 긍정(positive) 쌍과 부정(negative) 쌍을 구분하여 손실을 계산 ‘’’ import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim</p></div><div class="heading-wrapper"><h4 data-heading="간단한 대조 학습 모델 정의" dir="auto" class="heading" id="간단한_대조_학습_모델_정의"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>간단한 대조 학습 모델 정의</h4><div class="heading-children"><div><p dir="auto">class SimpleContrastiveModel(nn.Module): def&nbsp;<strong>init</strong>(self, embedding_dim=128): super(SimpleContrastiveModel, self).<strong>init</strong>() # CNN 기반 인코더 정의: 입력 이미지를 임베딩 벡터로 변환 self.encoder = nn.Sequential( nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1), # 1번째 레이어 (3 -&gt; 64) nn.ReLU(), # 활성화 함수 ReLU nn.MaxPool2d(kernel_size=2, stride=2), # 풀링 레이어 nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), # 2번째 레이어 (64 -&gt; 128) nn.ReLU(), # 활성화 함수 ReLU nn.MaxPool2d(kernel_size=2, stride=2), # 풀링 레이어 nn.Flatten(), # 출력 데이터를 1차원 벡터로 변환 nn.Linear(128 <em> 8 </em> 8, embedding_dim) # 완전 연결 레이어, 임베딩 차원으로 변환 )</p></div><div><pre><code>def forward(self, x):
    # 입력 이미지 x를 임베딩 벡터로 변환하고 정규화
    return F.normalize(self.encoder(x), dim=-1)
</code><button class="copy-code-button">Copy</button></pre></div></div></div><div class="heading-wrapper"><h4 data-heading="대조 학습 손실 함수 정의" dir="auto" class="heading" id="대조_학습_손실_함수_정의"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>대조 학습 손실 함수 정의</h4><div class="heading-children"><div><p dir="auto">def contrastive_loss(out1, out2, label): # 코사인 유사도 계산: 두 임베딩 벡터 간의 유사도 측정 cosine_similarity = F.cosine_similarity(out1, out2) # BCEWithLogitsLoss를 사용하여 대조 학습 손실 계산 bce_loss = nn.BCEWithLogitsLoss() # 코사인 유사도와 실제 lable을 사용하여 손실 계산 loss = bce_loss(cosine_similarity, label) return lossine_similarity, label) return loss</p></div></div></div><div class="heading-wrapper"><h4 data-heading="모델 초기화" dir="auto" class="heading" id="모델_초기화"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>모델 초기화</h4><div class="heading-children"><div><p dir="auto">model = SimpleContrastiveModel(embedding_dim=128)</p></div></div></div><div class="heading-wrapper"><h4 data-heading="Adam 옵티마이저 설정" dir="auto" class="heading" id="Adam_옵티마이저_설정"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Adam 옵티마이저 설정</h4><div class="heading-children"><div><p dir="auto">optimizer = optim.Adam(model.parameters(), lr=0.001)</p></div></div></div><div class="heading-wrapper"><h4 data-heading="예제 데이터 생성 (batch size: 16, channel: 3, height: 32, width: 32)" dir="auto" class="heading" id="예제_데이터_생성_(batch_size:_16,_channel:_3,_height:_32,_width:_32)"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>예제 데이터 생성 (batch size: 16, channel: 3, height: 32, width: 32)</h4><div class="heading-children"><div><p dir="auto">batch_size = 16 x1 = torch.randn(batch_size, 3, 32, 32) x2 = torch.randn(batch_size, 3, 32, 32)</p></div><div><p dir="auto">labels = torch.randint(0, 2, (batch_size,)).float() # 1: 같은 클래스, 0: 다른 클래스</p></div></div></div><div class="heading-wrapper"><h4 data-heading="모델 출력 계산" dir="auto" class="heading" id="모델_출력_계산"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>모델 출력 계산</h4><div class="heading-children"><div><p dir="auto">out1 = model(x1) out2 = model(x2)</p></div></div></div><div class="heading-wrapper"><h4 data-heading="대조 학습 손실 계산" dir="auto" class="heading" id="대조_학습_손실_계산"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>대조 학습 손실 계산</h4><div class="heading-children"><div><p dir="auto">loss = contrastive_loss(out1, out2, labels)</p></div></div></div><div class="heading-wrapper"><h4 data-heading="역전파 및 파라미터 업데이트" dir="auto" class="heading" id="역전파_및_파라미터_업데이트"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>역전파 및 파라미터 업데이트</h4><div class="heading-children"><div><p dir="auto">optimizer.zero_grad() loss.backward() optimizer.step()</p></div><div><p dir="auto">print(f’Loss: {loss.item()}’) ‘’’ ————————————————————————————————– ‘’’ import torch import torch.nn as nn import torch.optim as optim</p></div></div></div><div class="heading-wrapper"><h4 data-heading="SimpleContrastiveModel 클래스와 contrastive_loss 함수가 정의되어 있다고 가정합니다." dir="auto" class="heading" id="SimpleContrastiveModel_클래스와_contrastive_loss_함수가_정의되어_있다고_가정합니다."><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>SimpleContrastiveModel 클래스와 contrastive_loss 함수가 정의되어 있다고 가정합니다.</h4><div class="heading-children"></div></div><div class="heading-wrapper"><h4 data-heading="모델 초기화" dir="auto" class="heading" id="모델_초기화"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>모델 초기화</h4><div class="heading-children"><div><p dir="auto">model = SimpleContrastiveModel(embedding_dim=128)</p></div></div></div><div class="heading-wrapper"><h4 data-heading="옵티마이저 설정" dir="auto" class="heading" id="옵티마이저_설정"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>옵티마이저 설정</h4><div class="heading-children"><div><p dir="auto">optimizer = optim.Adam(model.parameters(), lr=0.001)</p></div></div></div><div class="heading-wrapper"><h4 data-heading="훈련 데이터 생성 (배치 크기: 16, 채널: 3, 높이: 32, 너비: 32)" dir="auto" class="heading" id="훈련_데이터_생성_(배치_크기:_16,_채널:_3,_높이:_32,_너비:_32)"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>훈련 데이터 생성 (배치 크기: 16, 채널: 3, 높이: 32, 너비: 32)</h4><div class="heading-children"><div><p dir="auto">batch_size = 16 x1_train = torch.randn(batch_size, 3, 32, 32) x2_train = torch.randn(batch_size, 3, 32, 32) train_labels = torch.randint(0, 2, (batch_size,)).float()</p></div></div></div><div class="heading-wrapper"><h4 data-heading="테스트 데이터 생성 (배치 크기: 8, 채널: 3, 높이: 32, 너비: 32)" dir="auto" class="heading" id="테스트_데이터_생성_(배치_크기:_8,_채널:_3,_높이:_32,_너비:_32)"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>테스트 데이터 생성 (배치 크기: 8, 채널: 3, 높이: 32, 너비: 32)</h4><div class="heading-children"><div><p dir="auto">x1_test = torch.randn(8, 3, 32, 32) x2_test = torch.randn(8, 3, 32, 32) test_labels = torch.randint(0, 2, (8,)).float()</p></div></div></div><div class="heading-wrapper"><h4 data-heading="모델 훈련" dir="auto" class="heading" id="모델_훈련"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>모델 훈련</h4><div class="heading-children"><div><p dir="auto">num_epochs = 10 for epoch in range(num_epochs): # 모델 출력 계산 out1_train = model(x1_train) out2_train = model(x2_train)</p></div><div><pre><code># 대조 학습 손실 계산
loss = contrastive_loss(out1_train, out2_train, train_labels)

# 역전파 및 파라미터 업데이트
optimizer.zero_grad()
loss.backward()
optimizer.step()

print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')
</code><button class="copy-code-button">Copy</button></pre></div></div></div><div class="heading-wrapper"><h4 data-heading="모델 테스트" dir="auto" class="heading" id="모델_테스트"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>모델 테스트</h4><div class="heading-children"><div><p dir="auto">with torch.no_grad(): out1_test = model(x1_test) out2_test = model(x2_test)</p></div><div><pre><code># 코사인 유사도 계산
cosine_similarity_test = torch.sigmoid(F.cosine_similarity(out1_test, out2_test))

# 예측 결과
predictions = (cosine_similarity_test &gt; 0.5).float()

# 정확도 계산
accuracy = (predictions == test_labels).float().mean()

print(f'Test Accuracy: {accuracy.item() * 100:.2f}%')

# 각 테스트 샘플에 대한 코사인 유사도와 실제 레이블 출력
print("Cosine Similarity and Labels:")
for i in range(len(test_labels)):
    print(f"Sample {i+1}: Cosine Similarity = {cosine_similarity_test[i].item():.4f}, Label = {test_labels[i].item()}, Prediction = {predictions[i].item()}")
</code><button class="copy-code-button">Copy</button></pre></div><div><p dir="auto">’’’ Epoch [1/10], Loss: 0.8842123746871948 Epoch [2/10], Loss: 0.9274642467498779 Epoch [3/10], Loss: 0.9250276684761047 Epoch [4/10], Loss: 0.9145865440368652 Epoch [5/10], Loss: 0.866182267665863 Epoch [6/10], Loss: 0.5781313180923462 Epoch [7/10], Loss: 0.557551383972168 Epoch [8/10], Loss: 0.5832924842834473 Epoch [9/10], Loss: 0.41409537196159363 Epoch [10/10], Loss: 0.4382629096508026 Test Accuracy: 12.50% Cosine Similarity and Labels: Sample 1: Cosine Similarity = 0.7111, Label = 0.0, Prediction = 1.0 Sample 2: Cosine Similarity = 0.7042, Label = 0.0, Prediction = 1.0 Sample 3: Cosine Similarity = 0.7109, Label = 0.0, Prediction = 1.0 Sample 4: Cosine Similarity = 0.7049, Label = 0.0, Prediction = 1.0 Sample 5: Cosine Similarity = 0.7111, Label = 1.0, Prediction = 1.0 Sample 6: Cosine Similarity = 0.7117, Label = 0.0, Prediction = 1.0 Sample 7: Cosine Similarity = 0.7063, Label = 0.0, Prediction = 1.0 Sample 8: Cosine Similarity = 0.7098, Label = 0.0, Prediction = 1.0</p></div><div><p dir="auto">문제점&nbsp;<strong>손실 값 감소</strong>&nbsp;훈련 중 손실 값이 감소하는 것은 모델이 훈련 데이터에 대해 학습하고 있음을 나타낸다. 그러나 손실 값의 감소가 매우 불규칙하고, 손실 값이 매우 높고 후반부에 급격히 감소하는 모양이다. 이는 모델이 안정적으로 학습되지 않았거나 데이터의 질과 양에 문제가 있을 수 있음을 의미한다.</p></div><div><p dir="auto"><strong>테스트 정확도</strong>&nbsp;테스트 정확도가 매우 낮다. 이는 모델이 테스트 데이터에 대해 거의 무작위로 예측하고 있음을 의미한다.</p></div><div><p dir="auto"><strong>코사인 유사도 및 예측</strong>&nbsp;코사인 유사도 값이 모든 샘플에서 매우 유사하게 높게 나타나고 있으며, 이는 모델이 제대로 된 임베딩을 학습하지 못하고 있다는 이야기다. 모든 샘플에 대해 거의 동일한 값을 출력하고 있으며, 이로 인해 예측이 실제 레이블과 일치하지 않는 상황이 발생한다.</p></div><div><p dir="auto">해결 방안&nbsp;<strong>데이터셋 품질 개선</strong>&nbsp;가상 데이터셋 대신 실제 데이터셋으로 모델을 훈련 가상 데이터는 모델 학습에 필요한 다양성과 복잡성이 부족할 수 있다.</p></div><div><p dir="auto"><strong>모델 구조 수정</strong>&nbsp;모델이 너무 단순하여 데이터의 복잡한 패턴을 학습하지 못할 수 있다. 더 깊고 복잡한 모델을 사용하거나, 현재 아키텍처에 더 많은 층을 추가하여 모델의 구조를 변경할 수 있다.</p></div><div><p dir="auto"><strong>학습 하이퍼파라미터 조정</strong>&nbsp;학습률을 조정하여 모델의 학습 속도를 최적화할 수 있다. 에포크 수를 늘려 더 오랜 시간 동안 학습하게 하여 성능을 개선 배치사이즈를 조정하여 학습 안정성을 도모 커널 사이즈를 조정하여 모델의 복잡성 및 특징에 대하여 학습</p></div><div><p dir="auto"><strong>손실 함수 및 학습 방식 검토</strong>&nbsp;BCEWithLogitsLoss를 사용하는 방법이 적절한지 확인해야 한다. 공부한 내용이라 사용하긴 하였지만, 적절한 방법인지에 대한 고려 없이 사용하여 잘못된 결과가 도출되었을 수도 있다. 코사인 유사도가 매우 좁은 범위에 몰려 있다면, 모델이 효과적으로 학습하지 못할 수 있다. 이를 위해 대조 학습 손실의 다른 변형을 사용하거나, 추가적인 정규화 기법을 도입할 수 있다.</p></div><div><p dir="auto"><strong>ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ--------</strong></p></div></div></div></div></div></div></div><div class="heading-wrapper"><h2 data-heading="인증샷" dir="auto" class="heading" id="인증샷"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>인증샷</h2><div class="heading-children"><div><p dir="auto"><span alt="team-blog-코딩황제들-2024-week6.모각코6일차회의인증.png" src="team-blog-코딩황제들-2024-week6.모각코6일차회의인증.png" class="internal-embed media-embed image-embed is-loaded"><img alt="team-blog-코딩황제들-2024-week6.모각코6일차회의인증.png" src="lib/media/team-blog-코딩황제들-2024-week6.모각코6일차회의인증.png"></span><br>
<span alt="team-blog-코딩황제들-2024-week6.모각코6일차시간인증.jpg" src="team-blog-코딩황제들-2024-week6.모각코6일차시간인증.jpg" class="internal-embed media-embed image-embed is-loaded"><img alt="team-blog-코딩황제들-2024-week6.모각코6일차시간인증.jpg" src="lib/media/team-blog-코딩황제들-2024-week6.모각코6일차시간인증.jpg"></span></p></div><div class="mod-footer"></div></div></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div class="tree-container mod-root nav-folder tree-item outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span></div><div class="tree-scroll-area tree-item-children nav-folder-children"><div class="tree-item mod-tree-folder nav-folder mod-collapsible is-collapsed" style="display: none;"></div><div class="tree-item" data-depth="1"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#계획"><div class="tree-item-contents heading-link" heading-name="계획"><span class="tree-item-title">계획</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#결과"><div class="tree-item-contents heading-link" heading-name="결과"><span class="tree-item-title">결과</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#준혁(팀장)"><div class="tree-item-contents heading-link" heading-name="준혁(팀장)"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">준혁(팀장)</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#목표:"><div class="tree-item-contents heading-link" heading-name="목표:"><span class="tree-item-title">목표:</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item mod-collapsible" data-depth="3"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#결과:"><div class="tree-item-contents heading-link" heading-name="결과:"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">결과:</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#1._EBGAN이란?"><div class="tree-item-contents heading-link" heading-name="1. EBGAN이란?"><span class="tree-item-title">1. 
EBGAN이란?
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#2._**전통적인_GAN의_기본_개념**"><div class="tree-item-contents heading-link" heading-name="2. **전통적인 GAN의 기본 개념**"><span class="tree-item-title">2. 
전통적인 GAN의 기본 개념
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#3._**EBGAN에서의_변화**"><div class="tree-item-contents heading-link" heading-name="3. **EBGAN에서의 변화**"><span class="tree-item-title">3. 
EBGAN에서의 변화
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#4._**EBGAN의_작동_방식**"><div class="tree-item-contents heading-link" heading-name="4. **EBGAN의 작동 방식**"><span class="tree-item-title">4. 
EBGAN의 작동 방식
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#5._**EBGAN의_장점**"><div class="tree-item-contents heading-link" heading-name="5. **EBGAN의 장점**"><span class="tree-item-title">5. 
EBGAN의 장점
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#6._**예시**"><div class="tree-item-contents heading-link" heading-name="6. **예시**"><span class="tree-item-title">6. 
예시
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#7._**EBGAN의_응용**"><div class="tree-item-contents heading-link" heading-name="7. **EBGAN의 응용**"><span class="tree-item-title">7. 
EBGAN의 응용
</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#세준"><div class="tree-item-contents heading-link" heading-name="세준"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">세준</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#목표:"><div class="tree-item-contents heading-link" heading-name="목표:"><span class="tree-item-title">목표:</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#결과:"><div class="tree-item-contents heading-link" heading-name="결과:"><span class="tree-item-title">결과:</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#우석"><div class="tree-item-contents heading-link" heading-name="우석"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">우석</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#목표:"><div class="tree-item-contents heading-link" heading-name="목표:"><span class="tree-item-title">목표:</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item mod-collapsible" data-depth="3"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#결과:"><div class="tree-item-contents heading-link" heading-name="결과:"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">결과:</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#판별자의_손실_함수"><div class="tree-item-contents heading-link" heading-name="판별자의 손실 함수"><span class="tree-item-title">판별자의 손실 함수</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#생성자의_손실_함수"><div class="tree-item-contents heading-link" heading-name="생성자의 손실 함수"><span class="tree-item-title">생성자의 손실 함수</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#채연"><div class="tree-item-contents heading-link" heading-name="채연"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">채연</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#목표:"><div class="tree-item-contents heading-link" heading-name="목표:"><span class="tree-item-title">목표:</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item mod-collapsible" data-depth="3"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#결과:"><div class="tree-item-contents heading-link" heading-name="결과:"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">결과:</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#간단한_대조_학습_모델_정의"><div class="tree-item-contents heading-link" heading-name="간단한 대조 학습 모델 정의"><span class="tree-item-title">간단한 대조 학습 모델 정의</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#대조_학습_손실_함수_정의"><div class="tree-item-contents heading-link" heading-name="대조 학습 손실 함수 정의"><span class="tree-item-title">대조 학습 손실 함수 정의</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#모델_초기화"><div class="tree-item-contents heading-link" heading-name="모델 초기화"><span class="tree-item-title">모델 초기화</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#Adam_옵티마이저_설정"><div class="tree-item-contents heading-link" heading-name="Adam 옵티마이저 설정"><span class="tree-item-title">Adam 옵티마이저 설정</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#예제_데이터_생성_(batch_size:_16,_channel:_3,_height:_32,_width:_32)"><div class="tree-item-contents heading-link" heading-name="예제 데이터 생성 (batch size: 16, channel: 3, height: 32, width: 32)"><span class="tree-item-title">예제 데이터 생성 (batch size: 16, channel: 3, height: 32, width: 32)</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#모델_출력_계산"><div class="tree-item-contents heading-link" heading-name="모델 출력 계산"><span class="tree-item-title">모델 출력 계산</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#대조_학습_손실_계산"><div class="tree-item-contents heading-link" heading-name="대조 학습 손실 계산"><span class="tree-item-title">대조 학습 손실 계산</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#역전파_및_파라미터_업데이트"><div class="tree-item-contents heading-link" heading-name="역전파 및 파라미터 업데이트"><span class="tree-item-title">역전파 및 파라미터 업데이트</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#SimpleContrastiveModel_클래스와_contrastive_loss_함수가_정의되어_있다고_가정합니다."><div class="tree-item-contents heading-link" heading-name="SimpleContrastiveModel 클래스와 contrastive_loss 함수가 정의되어 있다고 가정합니다."><span class="tree-item-title">SimpleContrastiveModel 클래스와 contrastive_loss 함수가 정의되어 있다고 가정합니다.</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#모델_초기화"><div class="tree-item-contents heading-link" heading-name="모델 초기화"><span class="tree-item-title">모델 초기화</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#옵티마이저_설정"><div class="tree-item-contents heading-link" heading-name="옵티마이저 설정"><span class="tree-item-title">옵티마이저 설정</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#훈련_데이터_생성_(배치_크기:_16,_채널:_3,_높이:_32,_너비:_32)"><div class="tree-item-contents heading-link" heading-name="훈련 데이터 생성 (배치 크기: 16, 채널: 3, 높이: 32, 너비: 32)"><span class="tree-item-title">훈련 데이터 생성 (배치 크기: 16, 채널: 3, 높이: 32, 너비: 32)</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#테스트_데이터_생성_(배치_크기:_8,_채널:_3,_높이:_32,_너비:_32)"><div class="tree-item-contents heading-link" heading-name="테스트 데이터 생성 (배치 크기: 8, 채널: 3, 높이: 32, 너비: 32)"><span class="tree-item-title">테스트 데이터 생성 (배치 크기: 8, 채널: 3, 높이: 32, 너비: 32)</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#모델_훈련"><div class="tree-item-contents heading-link" heading-name="모델 훈련"><span class="tree-item-title">모델 훈련</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#모델_테스트"><div class="tree-item-contents heading-link" heading-name="모델 테스트"><span class="tree-item-title">모델 테스트</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="team's-blog\코딩황제들\8월-18일-모각코.html#인증샷"><div class="tree-item-contents heading-link" heading-name="인증샷"><span class="tree-item-title">인증샷</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector(".sidebar-right"); rs.classList.add("is-collapsed"); if (window.innerWidth > 768) rs.classList.remove("is-collapsed"); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></body></html>